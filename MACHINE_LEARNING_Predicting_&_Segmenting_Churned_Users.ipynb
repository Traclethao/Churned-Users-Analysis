{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FuPYiqPR7tNf",
        "nCwZ7Isv3SjU",
        "aRJxQmxS6NK5",
        "3dyOspyr3Y_6",
        "v9ay3gg-9D-S",
        "AdgSsNEZ9owE",
        "4I-npZIM5K5b",
        "pZ2h__ks5iUz",
        "PgCdDulHTY9V",
        "XLoWiVnYToIb",
        "m0q2qOHn5odG",
        "VG-FwfgjPYBS",
        "drpwRmS28kIU",
        "8PSldh6z8rT_",
        "gUPOA6giRLl4",
        "k2e_t4iURVO3",
        "wnqa8tMC8vgi",
        "GxmS5rf7WCuY",
        "UMdAtZpfWtWU",
        "uLBlcqAAXJw5",
        "eGYhKZLMXm9X",
        "BFeqEM6tlCGq",
        "IvHuyoKMn0L8",
        "9ycsow1fn9Zv",
        "6w78MTyF8nff",
        "a_S1Mv71IH7i"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **SUPERVISED LEARNING**"
      ],
      "metadata": {
        "id": "FuPYiqPR7tNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. EDA"
      ],
      "metadata": {
        "id": "nCwZ7Isv3SjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Overview**"
      ],
      "metadata": {
        "id": "aRJxQmxS6NK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6VOaCd-i6Rlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "id": "oF4N3fuj6cQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(path+\"churn_prediction.xlsx\")\n",
        "print(df)"
      ],
      "metadata": {
        "id": "dYRh-Jut6ceq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "id": "HUDvXoP13oD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Handle Missing/Duplicate Values**"
      ],
      "metadata": {
        "id": "3dyOspyr3Y_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isna().sum())"
      ],
      "metadata": {
        "id": "x1tbTql27AYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe())"
      ],
      "metadata": {
        "id": "qq1Z0HrXocQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tenure, HourSpendOnApp, CouponUsed, DaySinceLastOrder have 0 in values => replace 0\n",
        "df['Tenure'].fillna(0, inplace=True)\n",
        "df['HourSpendOnApp'].fillna(0, inplace=True)\n",
        "df['CouponUsed'].fillna(0, inplace=True)\n",
        "df['DaySinceLastOrder'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "EuGA8nxwp9lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OrderAmountHikeFromlastYear is Percentage increases in order from last year\n",
        "# If the number orders last year = the number orders in this year => can have 0 in values => replace 0\n",
        "df['OrderAmountHikeFromlastYear'].fillna(0, inplace=True)\n",
        "\n",
        "# OrderCount is Total number of orders has been places in last month\n",
        "# If the customer did not buy anything last month => can have 0 in values => replace 0\n",
        "df['OrderCount'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "Y1woXzki2Wna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WarehouseToHome  => don't have 0 in values\n",
        "# check outlier\n",
        "sns.boxplot(df['WarehouseToHome'])\n"
      ],
      "metadata": {
        "id": "KVVGwv_9vRWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WarehouseToHome can cover outliers => replace median\n",
        "WarehouseToHome_median = df['WarehouseToHome'].median()\n",
        "df['WarehouseToHome'].fillna(WarehouseToHome_median, inplace=True)\n",
        "\n",
        "print(df.isna().sum())\n",
        "df.duplicated().any()"
      ],
      "metadata": {
        "id": "zUTM68BM1yDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().any()"
      ],
      "metadata": {
        "id": "Hwi1nqh758uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check imbalanced**"
      ],
      "metadata": {
        "id": "v9ay3gg-9D-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_ratio = df['Churn'].value_counts(normalize=True)\n",
        "label_ratio"
      ],
      "metadata": {
        "id": "8SOZVWHm9GNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Univariate Analysis**"
      ],
      "metadata": {
        "id": "AdgSsNEZ9owE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes.unique()"
      ],
      "metadata": {
        "id": "oGR9CfWy9ptd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_cols = df.select_dtypes(include=['object'])\n",
        "num_cols = df.select_dtypes(exclude=['object'])"
      ],
      "metadata": {
        "id": "Fo9ttLYu-AV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols.nunique()"
      ],
      "metadata": {
        "id": "KMEzoyD3-MHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CityTier'] = df['CityTier'].astype(object)\n",
        "\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "m9-o-w_9BqJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Transforms Features"
      ],
      "metadata": {
        "id": "4I-npZIM5K5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_columns = ['PreferredLoginDevice','CityTier','PreferredPaymentMode','Gender','PreferedOrderCat','MaritalStatus']\n",
        "data_encoded = pd.get_dummies(df, columns=list_columns, dtype='int')\n",
        "data_encoded = data_encoded.drop(columns=['CustomerID'])\n",
        "\n",
        "print(data_encoded.head())"
      ],
      "metadata": {
        "id": "uv8EpYeT5h9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Apply Random Forest model"
      ],
      "metadata": {
        "id": "pZ2h__ks5iUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Split train/test set & Normalization**"
      ],
      "metadata": {
        "id": "PgCdDulHTY9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x=data_encoded.drop('Churn', axis = 1)\n",
        "y=data_encoded[['Churn']]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Number data of train set: {len(x_train)}\")\n",
        "print(f\"Number data of test set: {len(x_test)}\")"
      ],
      "metadata": {
        "id": "z-sYeFJ4HUxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Scale Feature:\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_train)\n",
        "\n",
        "x_train_scaled = scaler.transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "qAdXfCuwOe8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Random Forest Classifier**"
      ],
      "metadata": {
        "id": "XLoWiVnYToIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "# Train a Random Forest classifier\n",
        "classifier = RandomForestClassifier(random_state=42)\n",
        "classifier.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = classifier.predict(x_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "RandomForest_accuracy = accuracy_score(y_test, y_pred)\n",
        "RandomForest_conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {RandomForest_accuracy:.2f}')\n",
        "print(f'Confusion Matrix:\\n{RandomForest_conf_matrix}')\n"
      ],
      "metadata": {
        "id": "t23ABaN-O10f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Show Feature Importance from model"
      ],
      "metadata": {
        "id": "m0q2qOHn5odG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_rand = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "clf_rand.fit(x_train_scaled, y_train)\n",
        "y_ranf_pre_train = clf_rand.predict(x_train_scaled)\n",
        "y_ranf_pre_test = clf_rand.predict(x_test_scaled)"
      ],
      "metadata": {
        "id": "kchnCYsV9TRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feats = {} # a dict to hold feature_name: feature_importance\n",
        "for feature, importance in zip(x_test.columns, clf_rand.feature_importances_):\n",
        "    feats[feature] = importance #add the name/value pair\n",
        "\n",
        "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
        "importances = importances.sort_values(by='Gini-importance', ascending=True)\n",
        "\n",
        "importances = importances.reset_index()\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.barh(importances.tail(20)['index'][:20], importances.tail(20)['Gini-importance'])\n",
        "\n",
        "plt.title('Feature Important')\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xDGQA4G4O8ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Choose top n features to analyse"
      ],
      "metadata": {
        "id": "VG-FwfgjPYBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get CustomerID and Feature Important\n",
        "Feature_Important = data_encoded[['Churn','Tenure', 'Complain', 'DaySinceLastOrder', 'CashbackAmount', 'MaritalStatus_Single', 'PreferedOrderCat_Mobile Phone']]\n",
        "\n",
        "print(Feature_Important)"
      ],
      "metadata": {
        "id": "B7t4EAQDch5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the churning users\n",
        "Feature_Important = Feature_Important[Feature_Important['Churn']==1]"
      ],
      "metadata": {
        "id": "PpOd2gFNc16o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Feature_Important = Feature_Important.drop(columns=['Churn'])\n",
        "print(Feature_Important)"
      ],
      "metadata": {
        "id": "VnQLL2CIc_0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UNSUPERVISED LEARNING**"
      ],
      "metadata": {
        "id": "drpwRmS28kIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dimension Reduction"
      ],
      "metadata": {
        "id": "k2e_t4iURVO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=3)\n",
        "pca.fit(Feature_Important)\n",
        "PCA_ds = pd.DataFrame(pca.transform(Feature_Important), columns=([\"col1\",\"col2\", \"col3\"]))\n",
        "PCA_ds"
      ],
      "metadata": {
        "id": "1iN2LLHxLD31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "UE1tYlrbR0H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Apply K-Means model"
      ],
      "metadata": {
        "id": "wnqa8tMC8vgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Choosing K:**"
      ],
      "metadata": {
        "id": "GxmS5rf7WCuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "ss = []\n",
        "max_clusters = 10\n",
        "for i in range(1, max_clusters+1):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "    kmeans.fit(PCA_ds)\n",
        "    # Inertia method returns WCSS for that model\n",
        "    ss.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow method\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(range(1, max_clusters+1), ss, marker='o', linestyle='--')\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "91cVr9aIV8o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Apply K-Means:**"
      ],
      "metadata": {
        "id": "UMdAtZpfWtWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
        "predicted_labels = kmeans.fit_predict(PCA_ds)\n",
        "\n",
        "PCA_ds['clusters']=predicted_labels\n",
        "Feature_Important['clusters']=predicted_labels"
      ],
      "metadata": {
        "id": "x1r8ccJKWp4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Feature_Important"
      ],
      "metadata": {
        "id": "jCc7z7dkh1Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Silhouette Score:**"
      ],
      "metadata": {
        "id": "uLBlcqAAXJw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "sil_score = silhouette_score(PCA_ds, predicted_labels)\n",
        "print(sil_score)"
      ],
      "metadata": {
        "id": "IpB15LKHXEQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Distribution of clusters:**"
      ],
      "metadata": {
        "id": "eGYhKZLMXm9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pal = [\"#682F2F\",\"#B9C0C9\", \"#9F8A78\",\"#F3AB60\"]\n",
        "pl = sns.countplot(x=Feature_Important[\"clusters\"], palette= pal)\n",
        "pl.set_title(\"Distribution Of The Clusters\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qTsJVFQCXnjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl = sns.scatterplot(data = Feature_Important,x=Feature_Important[\"Tenure\"], y=Feature_Important[\"CashbackAmount\"],hue=Feature_Important[\"clusters\"], palette= pal)\n",
        "pl.set_title(\"Cluster's Profile Based On CashbackAmount And Tenure\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hf5OY6Gk4GrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl = sns.scatterplot(data = Feature_Important,x=Feature_Important[\"DaySinceLastOrder\"], y=Feature_Important[\"CashbackAmount\"],hue=Feature_Important[\"clusters\"], palette= pal)\n",
        "pl.set_title(\"Cluster's Profile Based On CashbackAmount And DaySinceLastOrder\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tcM_K_wk5oL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl = sns.countplot(data = Feature_Important,x=Feature_Important[\"MaritalStatus_Single\"],hue=Feature_Important[\"clusters\"], palette= pal)\n",
        "pl.set_title(\"Cluster's Profile Based On MaritalStatus\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8UnfDXAiYRKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl = sns.countplot(data = Feature_Important,x=Feature_Important[\"Complain\"],hue=Feature_Important[\"clusters\"], palette= pal)\n",
        "pl.set_title(\"Cluster's Profile Based On Complain\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eLL3yDgluBre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl = sns.countplot(data = Feature_Important,x=Feature_Important[\"PreferedOrderCat_Mobile Phone\"],hue=Feature_Important[\"clusters\"], palette= pal)\n",
        "pl.set_title(\"Cluster's Profile Based On PreferedOrderCat\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "roCvH19_uQsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. GridSearchCV model"
      ],
      "metadata": {
        "id": "BFeqEM6tlCGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Split train/test set & Normalization**"
      ],
      "metadata": {
        "id": "IvHuyoKMn0L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = Feature_Important.drop('clusters', axis = 1)\n",
        "y2 = Feature_Important[['clusters']]\n",
        "\n",
        "\n",
        "x2_train, x2_test, y2_train, y2_test = train_test_split(x2,y2, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Number data of train set: {len(x2_train)}\")\n",
        "print(f\"Number data of test set: {len(x2_test)}\")"
      ],
      "metadata": {
        "id": "DGOo0P_ilYgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Scale Feature:\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x2_train)\n",
        "\n",
        "x2_train_scaled = scaler.transform(x2_train)\n",
        "x2_test_scaled = scaler.transform(x2_test)"
      ],
      "metadata": {
        "id": "8Us1Zfh7lBoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Apply Model**"
      ],
      "metadata": {
        "id": "9ycsow1fn9Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Use GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(clf_rand, param_grid, cv=5, scoring='balanced_accuracy')\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(x2_train_scaled, y2_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_clf = grid_search.best_estimator_\n",
        "accuracy = best_clf.score(x2_test_scaled, y2_test)\n",
        "print(\"Test set accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "sF0iHniz82Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Importance of Clusters**"
      ],
      "metadata": {
        "id": "6w78MTyF8nff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_rand.fit(x2_train_scaled, y2_train)\n",
        "y2_ranf_pre_train = clf_rand.predict(x2_train_scaled)\n",
        "y2_ranf_pre_test = clf_rand.predict(x2_test_scaled)"
      ],
      "metadata": {
        "id": "v8BRg0bqkuT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feats = {} # a dict to hold feature_name: feature_importance\n",
        "for feature, importance in zip(x2_test.columns, clf_rand.feature_importances_):\n",
        "    feats[feature] = importance #add the name/value pair\n",
        "\n",
        "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
        "importances = importances.sort_values(by='Gini-importance', ascending=True)\n",
        "\n",
        "importances = importances.reset_index()\n",
        "\n",
        "# Create bar chart\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.barh(importances.tail(20)['index'][:20], importances.tail(20)['Gini-importance'])\n",
        "\n",
        "plt.title('Feature Important')\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R2MBz7Cuk120"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}